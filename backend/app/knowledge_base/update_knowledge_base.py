from langchain.text_splitter import RecursiveCharacterTextSplitter
from backend.app.knowledge_base.vector_store import create_vector_store
from backend.app.knowledge_base.embeddings import create_embeddings_client
from backend.app.knowledge_base.blob_storage import create_blob_storage_document_loader


def update_knowledge_base(force_update: bool = False):
    '''
    Actualiza la base de conocimientos cargando documentos desde Azure Blob Storage,
    dividi√©ndolos en segmentos y subi√©ndolos a Azure AI Search.

    Args:
        force_update (bool): Si es True, fuerza la actualizaci√≥n incluso si ya hay documentos.
    '''
    
    # Inicializar comp√≥nentes para base de conocimientos
    print("üîÑ Inicializando componentes para la base de conocimientos...")
    embeddings_client = create_embeddings_client()
    vector_store = create_vector_store(embeddings_client.embed_query)
    loader = create_blob_storage_document_loader()

    # Verificar si ya hay documentos en el vector store
    try:
        existing_documents = vector_store.similarity_search("test", k=1)
        if existing_documents and not force_update:
            print("‚úÖ La base de conocimientos ya tiene documentos. No se requiere actualizaci√≥n.")
            return
    except Exception:
        # Si el √≠ndice no existe, debemos cargar los documentos.
        pass

    # Si no hay documentos, cargar y procesar los nuevos
    print("‚ö†Ô∏è  La base de conocimientos est√° vac√≠a o se ha forzado la actualizaci√≥n. Cargando documentos desde Azure Blob Storage...")
    documents: list = loader.load()

    if not documents:
        print("‚ùå No se encontraron documentos en el contenedor de Azure Blob Storage. No se realizar√° ninguna acci√≥n.")
        return

    print(f"üìÑ Se encontraron {len(documents)} documentos. Procesando y dividiendo...")
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)
    splitted_documents = text_splitter.split_documents(documents=documents)

    # Subir los documentos al vector store
    print(f"‚¨ÜÔ∏è  Subiendo {len(splitted_documents)} segmentos de documentos a Azure AI Search...")
    vector_store.add_documents(documents=splitted_documents)
    print("‚úÖ Base de conocimientos actualizada con √©xito.")